{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSE 391 Final Project - Stock Market Prediction\n",
    "<br>\n",
    "Team Members: Hannah Yao, Jonathan Yin, and Arjun Rao\n",
    "<br>\n",
    "<br>\n",
    "The intention of this notebook is to simply assess various basic machine learning models' scores.\n",
    "<br>\n",
    "Seeing successful various models from sklearn are will help us determine which types of models are good, and what models might be worth further pursuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of our train and test data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((500, 1), (500,), (167, 1), (167,))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------ Read and Process Data ------------------ #\n",
    "\n",
    "# I am replacing outliers instead of dropping\n",
    "df = pd.read_csv(\"stockdata.csv\", index_col='date', parse_dates=['date'])\n",
    "\n",
    "# Replace signal outliers with last observation\n",
    "sig_val = df['signal'].value_counts()\n",
    "criteria = df[ (df['signal'] <= 2) | (df['signal'] >= 400) ]\n",
    "df['signal'][criteria.index] = np.nan\n",
    "df['signal'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Replace spy_close_price outliers with last observation.\n",
    "# Carry last observation forward method (thing in stocks)\n",
    "sig_val = df['spy_close_price'].value_counts()\n",
    "criteria = df[ df['spy_close_price'] >= 500 ]\n",
    "df['spy_close_price'][criteria.index] = np.nan\n",
    "df['spy_close_price'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "X = df[['signal']]\n",
    "Y = df['spy_close_price']\n",
    "#We split using 75% of the data for training and 25% for testing\n",
    "X_train, X_test , Y_train , Y_test = train_test_split(X,Y,test_size=0.25,random_state=34)\n",
    "print(\"shapes of our train and test data:\")\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressors!\n",
    "<br> Note that, for each of these, we're just printing out the score. A summary of the scores is in the last cell. We are just looking to see what models are good. Our actual models for the final project are described in detail in our other ipynb files with R^2 values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987971103732035\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, Y_train)\n",
    "Y_pred = linreg.predict(X_test)\n",
    "score_lin = linreg.score(X_test, Y_test)\n",
    "print(score_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9831000506179806"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machines - note: takes a ridiculous amount of time for large datasets. Ours isn't that large though.\n",
    "# https://datascience.stackexchange.com/questions/989/svm-using-scikit-learn-runs-endlessly-and-never-completes-executio\n",
    "SVR = SVR()\n",
    "SVR.fit(X_train, Y_train)\n",
    "Y_pred = SVR.predict(X_test)\n",
    "score_SVR = SVR.score(X_test, Y_test)\n",
    "score_SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9850217122287265\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors = 3)\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "score_knn = knn.score(X_test, Y_test)\n",
    "print(score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9876279713415251\n"
     ]
    }
   ],
   "source": [
    "# Linear SVR (linear suppor vector regression)\n",
    "\n",
    "linear_SVR = LinearSVR()\n",
    "linear_SVR.fit(X_train, Y_train)\n",
    "Y_pred = linear_SVR.predict(X_test)\n",
    "score_linear_SVR = linear_SVR.score(X_test, Y_test)\n",
    "print(score_linear_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9856548936253497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjunrao/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X_train, Y_train)\n",
    "Y_pred = sgd.predict(X_test)\n",
    "score_sgd = sgd.score(X_test, Y_test)\n",
    "print(score_sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9792330423140401\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "score_decision_tree = decision_tree.score(X_test, Y_test)\n",
    "print(score_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9843053792874018\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "#Can change n_estimators as desired\n",
    "random_forest = RandomForestRegressor(n_estimators=30, max_depth=10, random_state=1)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, Y_train)\n",
    "\n",
    "score_random_forest = random_forest.score(X_test, Y_test)\n",
    "print(score_random_forest)\n",
    "\n",
    "good_ypreds_list.append(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.987971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVR</td>\n",
       "      <td>0.987628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>0.985655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.985022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.984305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.979233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model     Score\n",
       "1         Logistic Regression  0.987971\n",
       "4                  Linear SVR  0.987628\n",
       "3  Stochastic Gradient Decent  0.985655\n",
       "0                         KNN  0.985022\n",
       "2               Random Forest  0.984305\n",
       "5               Decision Tree  0.979233"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show models\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression', \n",
    "              'Random Forest', \n",
    "              'Stochastic Gradient Decent', 'Linear SVR', \n",
    "              'Decision Tree'],\n",
    "    'Score': [score_knn, score_lin, \n",
    "              score_random_forest,\n",
    "              score_sgd, score_linear_SVR, score_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly all of our models do extremely well in terms of predicting spy_close_price based on signal.\n",
    "<br>\n",
    "Logistic regression seems to be the best, but not by a significant margin; we will pursue this further in the regression_models ipynb.\n",
    "<br>\n",
    "One type of model we didn't use here was a perceptron or neural network; we explore a neural_network model in the simple_neural_network ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
